# RPA Scraping System

Sistema de coleta de dados de mÃºltiplas fontes web com gerenciamento de jobs atravÃ©s de filas de mensagens e API REST.

> ğŸ“‹ Para detalhes completos dos requisitos tÃ©cnicos, veja [REQUIREMENTS.md](REQUIREMENTS.md)

## âš ï¸ Template Base - PREENCHER ConfiguraÃ§Ãµes

Este repositÃ³rio contÃ©m uma **estrutura base completa** para um sistema RPA de scraping com:
- âœ… **Type Hints** em todo o cÃ³digo
- âœ… **DocumentaÃ§Ã£o completa** com docstrings
- âœ… **Testes unitÃ¡rios** prontos para execuÃ§Ã£o
- âœ… **GitHub Actions** configurado para CI/CD
- âœ… **Arquitetura completa**: FastAPI + RabbitMQ + PostgreSQL + Selenium + BeautifulSoup

### ğŸ“ O que vocÃª precisa PREENCHER:

1. **ConfiguraÃ§Ã£o no `.env`** (copie de `.env.example`):
   - Credenciais do PostgreSQL (`DATABASE_URL`)
   - Credenciais do RabbitMQ (`RABBITMQ_HOST`, `RABBITMQ_USER`, `RABBITMQ_PASSWORD`)
   - URLs dos sites para scraping (`HOCKEY_URL`, `OSCAR_URL`)

2. **Seletores HTML/CSS nos scrapers**:
   - `app/static_scraper/hockey.py`: Adaptar seletores CSS conforme HTML do site
   - `app/dynamic_scraper/oscar.py`: Adaptar seletores Selenium conforme DOM do site

3. **GitHub Actions** (opcional):
   - Configurar secrets para deploy no GCR (`.github/workflows/ci.yml`)

Todos os pontos marcados com `# PREENCHER:` ou `"PREENCHER_*"` devem ser configurados conforme seu ambiente e site alvo.

## Estrutura do Projeto

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/             # Config, DB e Rabbit (O essencial)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py     # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ database.py   # ConexÃ£o e sessÃ£o do banco
â”‚   â”‚   â””â”€â”€ rabbitmq.py   # ConexÃ£o e gerenciamento de filas
â”‚   â”œâ”€â”€ static_scraper/   # Hockey (BeautifulSoup)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ hockey.py     # Scraper para dados de Hockey
â”‚   â”œâ”€â”€ dynamic_scraper/  # Oscar (Selenium)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ oscar.py      # Scraper para dados de Oscar
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py         # DB (Job, HockeyData, OscarData)
â”‚   â”œâ”€â”€ schemas.py        # Pydantic (Request/Response)
â”‚   â”œâ”€â”€ worker.py         # O Consumer do RabbitMQ que chama os scrapers
â”‚   â””â”€â”€ main.py           # FastAPI (Endpoints e disparo de mensagens)
â”œâ”€â”€ tests/                # Testes de integraÃ§Ã£o
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py       # Fixtures e configuraÃ§Ã£o de testes
â”‚   â””â”€â”€ test_api.py       # Testes de integraÃ§Ã£o da API
â”œâ”€â”€ .env.example          # Exemplo de variÃ¡veis de ambiente
â”œâ”€â”€ docker-compose.yml    # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ Dockerfile            # Imagem Docker da aplicaÃ§Ã£o
â””â”€â”€ requirements.txt      # DependÃªncias Python
```

## Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚â”€â”€â”€â”€â–¶â”‚  RabbitMQ   â”‚â”€â”€â”€â”€â–¶â”‚   Workers   â”‚
â”‚    (API)    â”‚     â”‚   (Queue)   â”‚     â”‚  (Crawlers) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                       â”‚
       â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  PostgreSQL â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚    (Data)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Como Executar

### PrÃ©-requisitos

- Docker
- Docker Compose

### Passos

```bash
# 1. Copiar exemplo de variÃ¡veis de ambiente
cp .env.example .env

# 2. Subir os serviÃ§os
docker-compose up --build

# 3. Acessar os serviÃ§os
# API: http://localhost:8000
# API Docs: http://localhost:8000/docs
# RabbitMQ Management: http://localhost:15672
```

## Endpoints da API

```
# Agendar coletas
POST /crawl/hockey         â†’ Agenda coleta do Hockey (retorna job_id)
POST /crawl/oscar          â†’ Agenda coleta do Oscar (retorna job_id)
POST /crawl/all            â†’ Agenda ambas as coletas (retorna job_id)

# Gerenciar jobs
GET  /jobs                 â†’ Lista todos os jobs
GET  /jobs/{job_id}        â†’ Status e detalhes de um job

# Consultar resultados
GET  /jobs/{job_id}/results â†’ Resultados de um job especÃ­fico
GET  /results/hockey        â†’ Todos os dados coletados de Hockey
GET  /results/oscar         â†’ Todos os dados coletados de Oscar
```

## Desenvolvimento

### Ambiente Nix + direnv (Recomendado - Linux)

```bash
# Permitir direnv
direnv allow

# O ambiente serÃ¡ carregado automaticamente
```

### Testes

```bash
# Rodar todos os testes
pytest

# Rodar com coverage
pytest --cov=app tests/
```

### Linting

```bash
# Verificar cÃ³digo
ruff check app/ tests/

# Formatar cÃ³digo
black app/ tests/
```

## Stack TecnolÃ³gica

- **FastAPI** - Framework web
- **SQLAlchemy** - ORM para PostgreSQL
- **RabbitMQ** - Sistema de filas de mensagens
- **BeautifulSoup4** - Scraping de pÃ¡ginas estÃ¡ticas
- **Selenium** - Scraping de pÃ¡ginas dinÃ¢micas
- **Docker** - ContainerizaÃ§Ã£o
